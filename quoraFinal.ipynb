{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quoraFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4aHzgjG5bKIECNnJ0MrTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjeswinjacob/NLP_Lab_Solutions/blob/master/quoraFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dituzY5HcegU"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAL3bgWuO0v",
        "outputId": "7db0810b-f554-4723-de00-44cb3c3757c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('train.csv')\n",
        "df.dropna(axis=0, inplace=True) # axis = 0 drops Rows with missing values and inplace changes values in the same dataframe\n",
        "df.groupby(\"is_duplicate\")['id'].count().plot.bar()\n",
        "df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True) # Drop specified columns; axis = 0 drops by row\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Z1KNE5c2bp"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYZDudExbK7"
      },
      "source": [
        "def clean(text):\n",
        "    # Clean the text\n",
        "    text = re.sub(\"what's\", \"what is\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(\"can't\", \"can not\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"n't\", \" not \", text)\n",
        "    text = re.sub(\"\\'re\", \" are \", text)\n",
        "    text = re.sub(\"\\'d\", \" would \", text)\n",
        "    text = re.sub(\"\\'ll\", \" will \", text)\n",
        "\n",
        "    # Lemmatizing Text\n",
        "    lemmatizer = WordNetLemmatizer() \n",
        "    words = nltk.word_tokenize(text)\n",
        "    text = ' '.join([lemmatizer.lemmatize(w) for w in words])\n",
        "    \n",
        "    return text\n",
        "    \n",
        "df['question1'] = df['question1'].apply(clean) # axis = 0 by default and to apply clean on every row in given dataframe\n",
        "df['question2'] = df['question2'].apply(clean)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KomslrErvBca"
      },
      "source": [
        "Regularization Parameters Legend:\n",
        "\n",
        "* Gamma - Tree Complexity Parameter - Minimum loss reduction required to make a further partition on a leaf node of the tree. If Gain - Gamma = +ve, we keep node, else discard. So, we don't prune as long as we have a positive gain.\n",
        "\n",
        "* Alpha - L1 (Lasso) regularization on leaf weights - Larger values of Alpha helps us do away with useless features.\n",
        "\n",
        "* Lambda - L2 (Ridge) regularization on leaf weights - Introduces Bias to reduce Variance - Reduces Similarity score, so with gamma we can easily prune. Prunes and combines observations with other observations. Lambda also results in smaller output values.\n",
        "\n",
        "* scale_pos_weight set to ratio of negative class entities to positive class entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDuL_nrdLK7"
      },
      "source": [
        "**Model 1: BOW -> XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzQXDAQFqh5m",
        "outputId": "f3cfef92-e66b-4cb9-93e1-0d7f50fb48eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Countvectorizer lowercases all words by default and removes punctuation\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "# The fit method learns the vocabulary of all tokens in the documents\n",
        "count_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = count_vect.transform(df['question1'].values)\n",
        "trainq2_trans = count_vect.transform(df['question2'].values)\n",
        "\n",
        "import scipy\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = df['is_duplicate'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "[0]\tvalidation_0-aucpr:0.679638\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.70193\n",
            "[2]\tvalidation_0-aucpr:0.71836\n",
            "[3]\tvalidation_0-aucpr:0.729554\n",
            "[4]\tvalidation_0-aucpr:0.735555\n",
            "[5]\tvalidation_0-aucpr:0.74137\n",
            "[6]\tvalidation_0-aucpr:0.745527\n",
            "[7]\tvalidation_0-aucpr:0.750151\n",
            "[8]\tvalidation_0-aucpr:0.754121\n",
            "[9]\tvalidation_0-aucpr:0.758675\n",
            "[10]\tvalidation_0-aucpr:0.762979\n",
            "[11]\tvalidation_0-aucpr:0.767085\n",
            "[12]\tvalidation_0-aucpr:0.770508\n",
            "[13]\tvalidation_0-aucpr:0.772949\n",
            "[14]\tvalidation_0-aucpr:0.776118\n",
            "[15]\tvalidation_0-aucpr:0.778538\n",
            "[16]\tvalidation_0-aucpr:0.780527\n",
            "[17]\tvalidation_0-aucpr:0.782577\n",
            "[18]\tvalidation_0-aucpr:0.784386\n",
            "[19]\tvalidation_0-aucpr:0.786479\n",
            "[20]\tvalidation_0-aucpr:0.787911\n",
            "[21]\tvalidation_0-aucpr:0.788909\n",
            "[22]\tvalidation_0-aucpr:0.790754\n",
            "[23]\tvalidation_0-aucpr:0.792262\n",
            "[24]\tvalidation_0-aucpr:0.793442\n",
            "[25]\tvalidation_0-aucpr:0.794316\n",
            "[26]\tvalidation_0-aucpr:0.795235\n",
            "[27]\tvalidation_0-aucpr:0.79598\n",
            "[28]\tvalidation_0-aucpr:0.797275\n",
            "[29]\tvalidation_0-aucpr:0.797884\n",
            "[30]\tvalidation_0-aucpr:0.798519\n",
            "[31]\tvalidation_0-aucpr:0.798985\n",
            "[32]\tvalidation_0-aucpr:0.799807\n",
            "[33]\tvalidation_0-aucpr:0.800792\n",
            "[34]\tvalidation_0-aucpr:0.801711\n",
            "[35]\tvalidation_0-aucpr:0.802217\n",
            "[36]\tvalidation_0-aucpr:0.803273\n",
            "[37]\tvalidation_0-aucpr:0.803756\n",
            "[38]\tvalidation_0-aucpr:0.804919\n",
            "[39]\tvalidation_0-aucpr:0.805541\n",
            "[40]\tvalidation_0-aucpr:0.806081\n",
            "[41]\tvalidation_0-aucpr:0.806655\n",
            "[42]\tvalidation_0-aucpr:0.807214\n",
            "[43]\tvalidation_0-aucpr:0.807657\n",
            "[44]\tvalidation_0-aucpr:0.8082\n",
            "[45]\tvalidation_0-aucpr:0.808745\n",
            "[46]\tvalidation_0-aucpr:0.809106\n",
            "[47]\tvalidation_0-aucpr:0.809598\n",
            "[48]\tvalidation_0-aucpr:0.810267\n",
            "[49]\tvalidation_0-aucpr:0.810644\n",
            "[50]\tvalidation_0-aucpr:0.811449\n",
            "[51]\tvalidation_0-aucpr:0.811832\n",
            "[52]\tvalidation_0-aucpr:0.812203\n",
            "[53]\tvalidation_0-aucpr:0.812592\n",
            "[54]\tvalidation_0-aucpr:0.813007\n",
            "[55]\tvalidation_0-aucpr:0.813348\n",
            "[56]\tvalidation_0-aucpr:0.813892\n",
            "[57]\tvalidation_0-aucpr:0.814198\n",
            "[58]\tvalidation_0-aucpr:0.814584\n",
            "[59]\tvalidation_0-aucpr:0.81485\n",
            "[60]\tvalidation_0-aucpr:0.815111\n",
            "[61]\tvalidation_0-aucpr:0.815502\n",
            "[62]\tvalidation_0-aucpr:0.815887\n",
            "[63]\tvalidation_0-aucpr:0.816595\n",
            "[64]\tvalidation_0-aucpr:0.816911\n",
            "[65]\tvalidation_0-aucpr:0.817304\n",
            "[66]\tvalidation_0-aucpr:0.817714\n",
            "[67]\tvalidation_0-aucpr:0.818053\n",
            "[68]\tvalidation_0-aucpr:0.818296\n",
            "[69]\tvalidation_0-aucpr:0.818606\n",
            "[70]\tvalidation_0-aucpr:0.81905\n",
            "[71]\tvalidation_0-aucpr:0.819391\n",
            "[72]\tvalidation_0-aucpr:0.819817\n",
            "[73]\tvalidation_0-aucpr:0.820271\n",
            "[74]\tvalidation_0-aucpr:0.820764\n",
            "[75]\tvalidation_0-aucpr:0.820995\n",
            "[76]\tvalidation_0-aucpr:0.821304\n",
            "[77]\tvalidation_0-aucpr:0.821543\n",
            "[78]\tvalidation_0-aucpr:0.821759\n",
            "[79]\tvalidation_0-aucpr:0.822223\n",
            "[80]\tvalidation_0-aucpr:0.822477\n",
            "[81]\tvalidation_0-aucpr:0.822679\n",
            "[82]\tvalidation_0-aucpr:0.822871\n",
            "[83]\tvalidation_0-aucpr:0.823646\n",
            "[84]\tvalidation_0-aucpr:0.823804\n",
            "[85]\tvalidation_0-aucpr:0.823943\n",
            "[86]\tvalidation_0-aucpr:0.824184\n",
            "[87]\tvalidation_0-aucpr:0.824333\n",
            "[88]\tvalidation_0-aucpr:0.824603\n",
            "[89]\tvalidation_0-aucpr:0.824847\n",
            "[90]\tvalidation_0-aucpr:0.825067\n",
            "[91]\tvalidation_0-aucpr:0.825754\n",
            "[92]\tvalidation_0-aucpr:0.825976\n",
            "[93]\tvalidation_0-aucpr:0.826121\n",
            "[94]\tvalidation_0-aucpr:0.82626\n",
            "[95]\tvalidation_0-aucpr:0.826426\n",
            "[96]\tvalidation_0-aucpr:0.826596\n",
            "[97]\tvalidation_0-aucpr:0.826735\n",
            "[98]\tvalidation_0-aucpr:0.82698\n",
            "[99]\tvalidation_0-aucpr:0.827379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84     63756\n",
            "           1       0.72      0.77      0.74     37316\n",
            "\n",
            "    accuracy                           0.80    101072\n",
            "   macro avg       0.79      0.80      0.79    101072\n",
            "weighted avg       0.81      0.80      0.80    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r13GOGJ0X0fn"
      },
      "source": [
        "Legend:\n",
        "* Precision is out of all predictions of one class, how many are right. TP/ (TP + FP) eg. Out of all duplicate prediction, how many are actually duplicate\n",
        "\n",
        "* Recall(Senstivity) is out of all entities of one class, how many are correctly predicted. TP/ (TP + FN) eg. Out of all duplicate questions in dataset, how many are predicted correctly\n",
        "\n",
        "* f1-score = 2(Precision * Recall)/ (Precision + Recall) - Harmonic Mean of Precision and Recall\n",
        " f1-score = TP/ (TP + (FP + FN)/ 2)\n",
        "\n",
        "* Macro average is unweighted average of probabilities in both class.\n",
        "\n",
        "* Support is the number of actual occurrences of the class in the specified dataset. \n",
        "\n",
        "* Weighted average gives the support-weighted mean per label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr8hBPZgdUWj"
      },
      "source": [
        "**Model 2: TFIDF + XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRgSbOOexGzc",
        "outputId": "6039d5a8-1483-4d56-8151-14d6a21c924a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
        "tfidf_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = tfidf_vect.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect.transform(df['question2'].values)\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-aucpr:0.678644\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.702687\n",
            "[2]\tvalidation_0-aucpr:0.719437\n",
            "[3]\tvalidation_0-aucpr:0.731345\n",
            "[4]\tvalidation_0-aucpr:0.74073\n",
            "[5]\tvalidation_0-aucpr:0.747252\n",
            "[6]\tvalidation_0-aucpr:0.752934\n",
            "[7]\tvalidation_0-aucpr:0.758068\n",
            "[8]\tvalidation_0-aucpr:0.762637\n",
            "[9]\tvalidation_0-aucpr:0.767321\n",
            "[10]\tvalidation_0-aucpr:0.771125\n",
            "[11]\tvalidation_0-aucpr:0.774424\n",
            "[12]\tvalidation_0-aucpr:0.777103\n",
            "[13]\tvalidation_0-aucpr:0.780107\n",
            "[14]\tvalidation_0-aucpr:0.78265\n",
            "[15]\tvalidation_0-aucpr:0.785446\n",
            "[16]\tvalidation_0-aucpr:0.788364\n",
            "[17]\tvalidation_0-aucpr:0.790417\n",
            "[18]\tvalidation_0-aucpr:0.792057\n",
            "[19]\tvalidation_0-aucpr:0.793502\n",
            "[20]\tvalidation_0-aucpr:0.795442\n",
            "[21]\tvalidation_0-aucpr:0.797063\n",
            "[22]\tvalidation_0-aucpr:0.798316\n",
            "[23]\tvalidation_0-aucpr:0.799152\n",
            "[24]\tvalidation_0-aucpr:0.800078\n",
            "[25]\tvalidation_0-aucpr:0.80103\n",
            "[26]\tvalidation_0-aucpr:0.802783\n",
            "[27]\tvalidation_0-aucpr:0.803474\n",
            "[28]\tvalidation_0-aucpr:0.804241\n",
            "[29]\tvalidation_0-aucpr:0.804925\n",
            "[30]\tvalidation_0-aucpr:0.805898\n",
            "[31]\tvalidation_0-aucpr:0.806461\n",
            "[32]\tvalidation_0-aucpr:0.807262\n",
            "[33]\tvalidation_0-aucpr:0.808921\n",
            "[34]\tvalidation_0-aucpr:0.809483\n",
            "[35]\tvalidation_0-aucpr:0.809938\n",
            "[36]\tvalidation_0-aucpr:0.810796\n",
            "[37]\tvalidation_0-aucpr:0.811325\n",
            "[38]\tvalidation_0-aucpr:0.811882\n",
            "[39]\tvalidation_0-aucpr:0.812344\n",
            "[40]\tvalidation_0-aucpr:0.812722\n",
            "[41]\tvalidation_0-aucpr:0.813216\n",
            "[42]\tvalidation_0-aucpr:0.813715\n",
            "[43]\tvalidation_0-aucpr:0.814114\n",
            "[44]\tvalidation_0-aucpr:0.815501\n",
            "[45]\tvalidation_0-aucpr:0.816097\n",
            "[46]\tvalidation_0-aucpr:0.816686\n",
            "[47]\tvalidation_0-aucpr:0.817074\n",
            "[48]\tvalidation_0-aucpr:0.817519\n",
            "[49]\tvalidation_0-aucpr:0.817922\n",
            "[50]\tvalidation_0-aucpr:0.818154\n",
            "[51]\tvalidation_0-aucpr:0.819029\n",
            "[52]\tvalidation_0-aucpr:0.819377\n",
            "[53]\tvalidation_0-aucpr:0.819935\n",
            "[54]\tvalidation_0-aucpr:0.820199\n",
            "[55]\tvalidation_0-aucpr:0.820547\n",
            "[56]\tvalidation_0-aucpr:0.821002\n",
            "[57]\tvalidation_0-aucpr:0.821452\n",
            "[58]\tvalidation_0-aucpr:0.821763\n",
            "[59]\tvalidation_0-aucpr:0.822064\n",
            "[60]\tvalidation_0-aucpr:0.822466\n",
            "[61]\tvalidation_0-aucpr:0.822741\n",
            "[62]\tvalidation_0-aucpr:0.82321\n",
            "[63]\tvalidation_0-aucpr:0.823789\n",
            "[64]\tvalidation_0-aucpr:0.824139\n",
            "[65]\tvalidation_0-aucpr:0.824417\n",
            "[66]\tvalidation_0-aucpr:0.824766\n",
            "[67]\tvalidation_0-aucpr:0.825145\n",
            "[68]\tvalidation_0-aucpr:0.825515\n",
            "[69]\tvalidation_0-aucpr:0.825797\n",
            "[70]\tvalidation_0-aucpr:0.826122\n",
            "[71]\tvalidation_0-aucpr:0.826425\n",
            "[72]\tvalidation_0-aucpr:0.826754\n",
            "[73]\tvalidation_0-aucpr:0.827117\n",
            "[74]\tvalidation_0-aucpr:0.827382\n",
            "[75]\tvalidation_0-aucpr:0.827702\n",
            "[76]\tvalidation_0-aucpr:0.828104\n",
            "[77]\tvalidation_0-aucpr:0.828352\n",
            "[78]\tvalidation_0-aucpr:0.828595\n",
            "[79]\tvalidation_0-aucpr:0.828776\n",
            "[80]\tvalidation_0-aucpr:0.829004\n",
            "[81]\tvalidation_0-aucpr:0.829369\n",
            "[82]\tvalidation_0-aucpr:0.829541\n",
            "[83]\tvalidation_0-aucpr:0.829738\n",
            "[84]\tvalidation_0-aucpr:0.830067\n",
            "[85]\tvalidation_0-aucpr:0.830288\n",
            "[86]\tvalidation_0-aucpr:0.83055\n",
            "[87]\tvalidation_0-aucpr:0.830859\n",
            "[88]\tvalidation_0-aucpr:0.831285\n",
            "[89]\tvalidation_0-aucpr:0.831463\n",
            "[90]\tvalidation_0-aucpr:0.83186\n",
            "[91]\tvalidation_0-aucpr:0.832111\n",
            "[92]\tvalidation_0-aucpr:0.832306\n",
            "[93]\tvalidation_0-aucpr:0.832537\n",
            "[94]\tvalidation_0-aucpr:0.832761\n",
            "[95]\tvalidation_0-aucpr:0.832944\n",
            "[96]\tvalidation_0-aucpr:0.833126\n",
            "[97]\tvalidation_0-aucpr:0.833331\n",
            "[98]\tvalidation_0-aucpr:0.833514\n",
            "[99]\tvalidation_0-aucpr:0.833676\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85     63633\n",
            "           1       0.74      0.75      0.75     37439\n",
            "\n",
            "    accuracy                           0.81    101072\n",
            "   macro avg       0.80      0.80      0.80    101072\n",
            "weighted avg       0.81      0.81      0.81    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybryLUUsdfJu"
      },
      "source": [
        "**Model 3: Character Level TFIDF -> XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnvkOr_JLDaW",
        "outputId": "048eaa79-f42b-473e-ad13-a5037806620d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,4))\n",
        "tfidf_vect_ngram_chars.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = tfidf_vect_ngram_chars.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect_ngram_chars.transform(df['question2'].values)\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-aucpr:0.656739\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.71425\n",
            "[2]\tvalidation_0-aucpr:0.739088\n",
            "[3]\tvalidation_0-aucpr:0.754692\n",
            "[4]\tvalidation_0-aucpr:0.766862\n",
            "[5]\tvalidation_0-aucpr:0.776422\n",
            "[6]\tvalidation_0-aucpr:0.784029\n",
            "[7]\tvalidation_0-aucpr:0.790575\n",
            "[8]\tvalidation_0-aucpr:0.79483\n",
            "[9]\tvalidation_0-aucpr:0.79899\n",
            "[10]\tvalidation_0-aucpr:0.803742\n",
            "[11]\tvalidation_0-aucpr:0.807545\n",
            "[12]\tvalidation_0-aucpr:0.810842\n",
            "[13]\tvalidation_0-aucpr:0.813623\n",
            "[14]\tvalidation_0-aucpr:0.816389\n",
            "[15]\tvalidation_0-aucpr:0.81845\n",
            "[16]\tvalidation_0-aucpr:0.821171\n",
            "[17]\tvalidation_0-aucpr:0.823928\n",
            "[18]\tvalidation_0-aucpr:0.826198\n",
            "[19]\tvalidation_0-aucpr:0.828533\n",
            "[20]\tvalidation_0-aucpr:0.830801\n",
            "[21]\tvalidation_0-aucpr:0.832707\n",
            "[22]\tvalidation_0-aucpr:0.834134\n",
            "[23]\tvalidation_0-aucpr:0.835662\n",
            "[24]\tvalidation_0-aucpr:0.837661\n",
            "[25]\tvalidation_0-aucpr:0.838971\n",
            "[26]\tvalidation_0-aucpr:0.840289\n",
            "[27]\tvalidation_0-aucpr:0.841598\n",
            "[28]\tvalidation_0-aucpr:0.84284\n",
            "[29]\tvalidation_0-aucpr:0.844032\n",
            "[30]\tvalidation_0-aucpr:0.845153\n",
            "[31]\tvalidation_0-aucpr:0.846419\n",
            "[32]\tvalidation_0-aucpr:0.847391\n",
            "[33]\tvalidation_0-aucpr:0.848157\n",
            "[34]\tvalidation_0-aucpr:0.84954\n",
            "[35]\tvalidation_0-aucpr:0.85073\n",
            "[36]\tvalidation_0-aucpr:0.851317\n",
            "[37]\tvalidation_0-aucpr:0.852386\n",
            "[38]\tvalidation_0-aucpr:0.85349\n",
            "[39]\tvalidation_0-aucpr:0.854209\n",
            "[40]\tvalidation_0-aucpr:0.855066\n",
            "[41]\tvalidation_0-aucpr:0.85579\n",
            "[42]\tvalidation_0-aucpr:0.856703\n",
            "[43]\tvalidation_0-aucpr:0.857439\n",
            "[44]\tvalidation_0-aucpr:0.858233\n",
            "[45]\tvalidation_0-aucpr:0.858896\n",
            "[46]\tvalidation_0-aucpr:0.85956\n",
            "[47]\tvalidation_0-aucpr:0.860212\n",
            "[48]\tvalidation_0-aucpr:0.860861\n",
            "[49]\tvalidation_0-aucpr:0.861465\n",
            "[50]\tvalidation_0-aucpr:0.862118\n",
            "[51]\tvalidation_0-aucpr:0.862485\n",
            "[52]\tvalidation_0-aucpr:0.863018\n",
            "[53]\tvalidation_0-aucpr:0.863738\n",
            "[54]\tvalidation_0-aucpr:0.864262\n",
            "[55]\tvalidation_0-aucpr:0.864845\n",
            "[56]\tvalidation_0-aucpr:0.865221\n",
            "[57]\tvalidation_0-aucpr:0.86587\n",
            "[58]\tvalidation_0-aucpr:0.866356\n",
            "[59]\tvalidation_0-aucpr:0.866806\n",
            "[60]\tvalidation_0-aucpr:0.867175\n",
            "[61]\tvalidation_0-aucpr:0.867559\n",
            "[62]\tvalidation_0-aucpr:0.868018\n",
            "[63]\tvalidation_0-aucpr:0.868384\n",
            "[64]\tvalidation_0-aucpr:0.868716\n",
            "[65]\tvalidation_0-aucpr:0.868936\n",
            "[66]\tvalidation_0-aucpr:0.869344\n",
            "[67]\tvalidation_0-aucpr:0.869562\n",
            "[68]\tvalidation_0-aucpr:0.869746\n",
            "[69]\tvalidation_0-aucpr:0.870027\n",
            "[70]\tvalidation_0-aucpr:0.870148\n",
            "[71]\tvalidation_0-aucpr:0.870419\n",
            "[72]\tvalidation_0-aucpr:0.870751\n",
            "[73]\tvalidation_0-aucpr:0.871007\n",
            "[74]\tvalidation_0-aucpr:0.871241\n",
            "[75]\tvalidation_0-aucpr:0.87145\n",
            "[76]\tvalidation_0-aucpr:0.871633\n",
            "[77]\tvalidation_0-aucpr:0.871931\n",
            "[78]\tvalidation_0-aucpr:0.872349\n",
            "[79]\tvalidation_0-aucpr:0.872523\n",
            "[80]\tvalidation_0-aucpr:0.872836\n",
            "[81]\tvalidation_0-aucpr:0.87302\n",
            "[82]\tvalidation_0-aucpr:0.873275\n",
            "[83]\tvalidation_0-aucpr:0.87362\n",
            "[84]\tvalidation_0-aucpr:0.873794\n",
            "[85]\tvalidation_0-aucpr:0.873968\n",
            "[86]\tvalidation_0-aucpr:0.874107\n",
            "[87]\tvalidation_0-aucpr:0.874331\n",
            "[88]\tvalidation_0-aucpr:0.874416\n",
            "[89]\tvalidation_0-aucpr:0.874638\n",
            "[90]\tvalidation_0-aucpr:0.874793\n",
            "[91]\tvalidation_0-aucpr:0.874985\n",
            "[92]\tvalidation_0-aucpr:0.875084\n",
            "[93]\tvalidation_0-aucpr:0.875219\n",
            "[94]\tvalidation_0-aucpr:0.875443\n",
            "[95]\tvalidation_0-aucpr:0.875551\n",
            "[96]\tvalidation_0-aucpr:0.875684\n",
            "[97]\tvalidation_0-aucpr:0.8759\n",
            "[98]\tvalidation_0-aucpr:0.876065\n",
            "[99]\tvalidation_0-aucpr:0.876244\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87     63633\n",
            "           1       0.81      0.75      0.77     37439\n",
            "\n",
            "    accuracy                           0.84    101072\n",
            "   macro avg       0.83      0.82      0.82    101072\n",
            "weighted avg       0.84      0.84      0.84    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzq6vWoDv1sz"
      },
      "source": [
        "**Conclusion**: Three different models were used to classify the pairs of questions as duplicate or not duplicate. The word level BOW model gave an accuracy of 80%, the word level TFIDF gave an accuracy of 81% - a slightly better improvement owing to the removal of useless words. The character level TFIDF consisting of bigrams, trigrams, and 4-grams gave the best accuracy of 84%. This is owing to the reason that there are various different words with the same meaning, which can't be captured by word level BOW or word level TFIDF eg. lover and loving. Thus, where word level BOW and TFIDF lose out on valuable information, character level n-gram TFIDF can capture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86FKISONxxU0"
      },
      "source": [
        "**Future Enhancements**: \n",
        "* Cosine distance, and the Word Mover's Distance can be used to capture more information from the questions to help classify with more accuracy. \n",
        "\n",
        "* Combining more than one model.\n",
        "\n",
        "* Further hyperparameter tuning using gridSearch can lead to further improvement of accuracy.\n",
        "\n",
        "* Deep learning models could be experimented with"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7oCidLuGoZF"
      },
      "source": [
        "Sources/ References:\n",
        "1. Finding Similar Quora Questions with BOW, TFIDF and Xgboost.\n",
        "Source: https://towardsdatascience.com/finding-similar-quora-questions-with-bow-tfidf-andrandom-forest-c54ad88d1370\n",
        "2. XGBoost in Python from Start to Finish.\n",
        "Source:https://www.youtube.com/watch?v=GrJP9FLV3FE&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=63\n",
        "3. Machine learning playlist by Josh Starmer.\n",
        "Source: https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\n",
        "4. Feature Engineering for NLP in Python.\n",
        "Source: https://learn.datacamp.com/courses/feature-engineering-for-nlp-in-python\n",
        "5. Extreme Gradient Boosting with XGBoost.\n",
        "Source: https://learn.datacamp.com/courses/extreme-gradient-boosting-with-xgboost\n",
        "6. XgBoost Documentation.\n",
        "Source: https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
        "7. Count Vectorizer Documentation.\n",
        "Source:https://scikitlearn.org/stable/modules/generated/sklearn.feature_extraction.text.Count\n",
        "Vectorizer.html\n",
        "8. TFIDF Vectorizer Documentation:\n",
        "Source:https://scikitlearn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "9. Why is XGBoost among most used machine learning method on Kaggle?\n",
        "Source: https://www.quora.com/Why-is-XGBoost-among-most-used-machine-learning-methodon-Kaggle\n",
        "10. Quora Question Pairs dataset.\n",
        "Source: https://www.kaggle.com/c/quora-question-pairs/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR3wl1-qgvNE"
      },
      "source": [
        "**Model 4: POS + XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n8SQSxLiuru",
        "outputId": "48a1bfb8-7f3e-4f29-e638-058d4de67454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "def POS(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    tags = nltk.pos_tag(words)\n",
        "    pos = ' '.join([t[1] for t in tags])\n",
        "    return pos\n",
        "    \n",
        "df['POS1'] = df['question1'].apply(POS) # axis = 0 by default and to apply POS on every row in given dataframe\n",
        "df['POS2'] = df['question2'].apply(POS)\n",
        "\n",
        "a = 0 \n",
        "for i in range(a,a+10):\n",
        "    print(df.POS1[i])\n",
        "    print(df.POS2[i])\n",
        "    print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WP VBZ DT NN IN NN RB TO VB IN NN NN IN NN .\n",
            "WP VBZ DT NN IN NN RB TO VB IN NN NN .\n",
            "\n",
            "WP VBZ DT NN IN NNP ( NNP ) NNP .\n",
            "WP MD VB IN DT JJ NN VBD DT NNP ( NNP ) NN RB .\n",
            "\n",
            "WRB MD PRP VB DT NN IN PRP$ JJ NN IN VBG DT NNP .\n",
            "WRB MD NNP NN VB VBN IN VBG IN NNP .\n",
            "\n",
            "WRB VBP PRP RB RB RB . WRB MD PRP VB PRP .\n",
            "IN DT NN WRB NNP NN VBD CD ( CD ) NNP NNP NNP VBZ VBN IN CD .\n",
            "\n",
            "WDT CD NN IN NN NN NN , NN , NN CC NN NN IN .\n",
            "JJ NN MD VB IN NN NN .\n",
            "\n",
            "NN : PRP VBP DT NNP NNP NNP NN CC NN NN : WP VBZ DT VBP IN PRP .\n",
            "PRP VBP DT JJ NNP ( NNP , NNP CC NN IN NNP ) WP VBZ DT VB IN PRP .\n",
            "\n",
            "MD PRP VB IN .\n",
            "WP VBZ JJ JJ CC RB IN NN CC NN NNS .\n",
            "\n",
            "WRB MD PRP VB DT JJ NN .\n",
            "WP MD PRP VB TO VB DT JJ NN .\n",
            "\n",
            "WRB VBP PRP VB JJ RB IN NNS .\n",
            "WRB VBP PRP VB `` CC '' RB IN `` CC '' .\n",
            "\n",
            "NNP ( NN ) : MD PRP VB PRP$ NNP NNP NNP .\n",
            "WRB VBP PRP VB NNP NNP IN JJ NN .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DhZ8aKXbDLp",
        "outputId": "888bc10c-ded5-4884-d0f1-8af40f866fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Countvectorizer lowercases all words by default and removes punctuation\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "# The fit method learns the vocabulary of all tokens in the documents\n",
        "count_vect.fit(pd.concat((df['POS1'],df['POS2'])).unique())\n",
        "\n",
        "trainq1_trans = count_vect.transform(df['POS1'].values)\n",
        "trainq2_trans = count_vect.transform(df['POS2'].values)\n",
        "\n",
        "import scipy\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = df['is_duplicate'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "[0]\tvalidation_0-aucpr:0.600182\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.632764\n",
            "[2]\tvalidation_0-aucpr:0.650587\n",
            "[3]\tvalidation_0-aucpr:0.660744\n",
            "[4]\tvalidation_0-aucpr:0.667038\n",
            "[5]\tvalidation_0-aucpr:0.67228\n",
            "[6]\tvalidation_0-aucpr:0.678098\n",
            "[7]\tvalidation_0-aucpr:0.681992\n",
            "[8]\tvalidation_0-aucpr:0.68531\n",
            "[9]\tvalidation_0-aucpr:0.688047\n",
            "[10]\tvalidation_0-aucpr:0.692461\n",
            "[11]\tvalidation_0-aucpr:0.695726\n",
            "[12]\tvalidation_0-aucpr:0.698929\n",
            "[13]\tvalidation_0-aucpr:0.701506\n",
            "[14]\tvalidation_0-aucpr:0.704328\n",
            "[15]\tvalidation_0-aucpr:0.706722\n",
            "[16]\tvalidation_0-aucpr:0.709388\n",
            "[17]\tvalidation_0-aucpr:0.711776\n",
            "[18]\tvalidation_0-aucpr:0.71392\n",
            "[19]\tvalidation_0-aucpr:0.715749\n",
            "[20]\tvalidation_0-aucpr:0.718441\n",
            "[21]\tvalidation_0-aucpr:0.720477\n",
            "[22]\tvalidation_0-aucpr:0.721989\n",
            "[23]\tvalidation_0-aucpr:0.723459\n",
            "[24]\tvalidation_0-aucpr:0.724459\n",
            "[25]\tvalidation_0-aucpr:0.725566\n",
            "[26]\tvalidation_0-aucpr:0.726842\n",
            "[27]\tvalidation_0-aucpr:0.728255\n",
            "[28]\tvalidation_0-aucpr:0.729432\n",
            "[29]\tvalidation_0-aucpr:0.730413\n",
            "[30]\tvalidation_0-aucpr:0.731671\n",
            "[31]\tvalidation_0-aucpr:0.732705\n",
            "[32]\tvalidation_0-aucpr:0.73361\n",
            "[33]\tvalidation_0-aucpr:0.734667\n",
            "[34]\tvalidation_0-aucpr:0.735359\n",
            "[35]\tvalidation_0-aucpr:0.736057\n",
            "[36]\tvalidation_0-aucpr:0.736726\n",
            "[37]\tvalidation_0-aucpr:0.737299\n",
            "[38]\tvalidation_0-aucpr:0.737934\n",
            "[39]\tvalidation_0-aucpr:0.738509\n",
            "[40]\tvalidation_0-aucpr:0.739139\n",
            "[41]\tvalidation_0-aucpr:0.739658\n",
            "[42]\tvalidation_0-aucpr:0.740136\n",
            "[43]\tvalidation_0-aucpr:0.740603\n",
            "[44]\tvalidation_0-aucpr:0.741078\n",
            "[45]\tvalidation_0-aucpr:0.741594\n",
            "[46]\tvalidation_0-aucpr:0.742116\n",
            "[47]\tvalidation_0-aucpr:0.742683\n",
            "[48]\tvalidation_0-aucpr:0.743073\n",
            "[49]\tvalidation_0-aucpr:0.743399\n",
            "[50]\tvalidation_0-aucpr:0.743753\n",
            "[51]\tvalidation_0-aucpr:0.744133\n",
            "[52]\tvalidation_0-aucpr:0.744651\n",
            "[53]\tvalidation_0-aucpr:0.745024\n",
            "[54]\tvalidation_0-aucpr:0.745457\n",
            "[55]\tvalidation_0-aucpr:0.745723\n",
            "[56]\tvalidation_0-aucpr:0.74606\n",
            "[57]\tvalidation_0-aucpr:0.746216\n",
            "[58]\tvalidation_0-aucpr:0.746665\n",
            "[59]\tvalidation_0-aucpr:0.747128\n",
            "[60]\tvalidation_0-aucpr:0.747363\n",
            "[61]\tvalidation_0-aucpr:0.747512\n",
            "[62]\tvalidation_0-aucpr:0.747706\n",
            "[63]\tvalidation_0-aucpr:0.747911\n",
            "[64]\tvalidation_0-aucpr:0.747986\n",
            "[65]\tvalidation_0-aucpr:0.748283\n",
            "[66]\tvalidation_0-aucpr:0.748477\n",
            "[67]\tvalidation_0-aucpr:0.748789\n",
            "[68]\tvalidation_0-aucpr:0.749063\n",
            "[69]\tvalidation_0-aucpr:0.749285\n",
            "[70]\tvalidation_0-aucpr:0.749371\n",
            "[71]\tvalidation_0-aucpr:0.749511\n",
            "[72]\tvalidation_0-aucpr:0.749681\n",
            "[73]\tvalidation_0-aucpr:0.749932\n",
            "[74]\tvalidation_0-aucpr:0.750114\n",
            "[75]\tvalidation_0-aucpr:0.750287\n",
            "[76]\tvalidation_0-aucpr:0.750351\n",
            "[77]\tvalidation_0-aucpr:0.750466\n",
            "[78]\tvalidation_0-aucpr:0.750722\n",
            "[79]\tvalidation_0-aucpr:0.750876\n",
            "[80]\tvalidation_0-aucpr:0.750981\n",
            "[81]\tvalidation_0-aucpr:0.751067\n",
            "[82]\tvalidation_0-aucpr:0.751181\n",
            "[83]\tvalidation_0-aucpr:0.751308\n",
            "[84]\tvalidation_0-aucpr:0.751465\n",
            "[85]\tvalidation_0-aucpr:0.751715\n",
            "[86]\tvalidation_0-aucpr:0.751956\n",
            "[87]\tvalidation_0-aucpr:0.752188\n",
            "[88]\tvalidation_0-aucpr:0.752255\n",
            "[89]\tvalidation_0-aucpr:0.752347\n",
            "[90]\tvalidation_0-aucpr:0.752403\n",
            "[91]\tvalidation_0-aucpr:0.752494\n",
            "[92]\tvalidation_0-aucpr:0.752666\n",
            "[93]\tvalidation_0-aucpr:0.752759\n",
            "[94]\tvalidation_0-aucpr:0.752852\n",
            "[95]\tvalidation_0-aucpr:0.753008\n",
            "[96]\tvalidation_0-aucpr:0.753142\n",
            "[97]\tvalidation_0-aucpr:0.753233\n",
            "[98]\tvalidation_0-aucpr:0.753365\n",
            "[99]\tvalidation_0-aucpr:0.753461\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.81     63756\n",
            "           1       0.68      0.69      0.68     37316\n",
            "\n",
            "    accuracy                           0.76    101072\n",
            "   macro avg       0.75      0.75      0.75    101072\n",
            "weighted avg       0.77      0.76      0.77    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZaFQSuZjOZ"
      },
      "source": [
        "**Model 5: POS + NER + XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBU-ItSih0u",
        "outputId": "7ffb0f96-c5ec-4718-daf4-f462e935a03e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "m = spacy.load('en_core_web_sm')\n",
        "\n",
        "def NER(text):\n",
        "    tagged = m(text)\n",
        "    ner = ' '.join([ent.label_ for ent in tagged.ents])\n",
        "    return ner\n",
        "    \n",
        "df['NER1'] = df['question1'].apply(NER) # axis = 0 by default and to apply NER on every row in given dataframe\n",
        "df['NER2'] = df['question2'].apply(NER)\n",
        "\n",
        "a = 0 \n",
        "for i in range(a,a+10):\n",
        "    print(df.NER1[i])\n",
        "    print(df.NER2[i])\n",
        "    print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPE\n",
            "\n",
            "\n",
            "GPE\n",
            "NORP\n",
            "\n",
            "ORG\n",
            "ORG\n",
            "\n",
            "\n",
            "CARDINAL\n",
            "\n",
            "CARDINAL\n",
            "\n",
            "\n",
            "PERSON\n",
            "ORG ORG PERSON GPE\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ORG PERSON\n",
            "ORG\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMPr1ahgqbTM",
        "outputId": "a14e5b75-1c15-46d4-e4a0-245345751d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Countvectorizer lowercases all words by default and removes punctuation\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "# The fit method learns the vocabulary of all tokens in the documents\n",
        "count_vect.fit(pd.concat((df['POS1'],df['POS2'],df['NER1'],df['NER2'])).unique())\n",
        "\n",
        "trainq1_trans_NER = count_vect.transform(df['NER1'].values)\n",
        "trainq2_trans_NER = count_vect.transform(df['NER2'].values)\n",
        "trainq1_trans_POS = count_vect.transform(df['POS1'].values)\n",
        "trainq2_trans_POS = count_vect.transform(df['POS2'].values)\n",
        "\n",
        "import scipy\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans, trainq1_trans_POS, trainq2_trans_POS))\n",
        "y = df['is_duplicate'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "[0]\tvalidation_0-aucpr:0.614024\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.650278\n",
            "[2]\tvalidation_0-aucpr:0.665026\n",
            "[3]\tvalidation_0-aucpr:0.673595\n",
            "[4]\tvalidation_0-aucpr:0.680491\n",
            "[5]\tvalidation_0-aucpr:0.684417\n",
            "[6]\tvalidation_0-aucpr:0.689242\n",
            "[7]\tvalidation_0-aucpr:0.693111\n",
            "[8]\tvalidation_0-aucpr:0.698108\n",
            "[9]\tvalidation_0-aucpr:0.701985\n",
            "[10]\tvalidation_0-aucpr:0.704777\n",
            "[11]\tvalidation_0-aucpr:0.709226\n",
            "[12]\tvalidation_0-aucpr:0.712171\n",
            "[13]\tvalidation_0-aucpr:0.715733\n",
            "[14]\tvalidation_0-aucpr:0.718554\n",
            "[15]\tvalidation_0-aucpr:0.721425\n",
            "[16]\tvalidation_0-aucpr:0.724042\n",
            "[17]\tvalidation_0-aucpr:0.726012\n",
            "[18]\tvalidation_0-aucpr:0.728188\n",
            "[19]\tvalidation_0-aucpr:0.73058\n",
            "[20]\tvalidation_0-aucpr:0.732687\n",
            "[21]\tvalidation_0-aucpr:0.73457\n",
            "[22]\tvalidation_0-aucpr:0.736848\n",
            "[23]\tvalidation_0-aucpr:0.738719\n",
            "[24]\tvalidation_0-aucpr:0.740269\n",
            "[25]\tvalidation_0-aucpr:0.741965\n",
            "[26]\tvalidation_0-aucpr:0.743144\n",
            "[27]\tvalidation_0-aucpr:0.744235\n",
            "[28]\tvalidation_0-aucpr:0.745633\n",
            "[29]\tvalidation_0-aucpr:0.746967\n",
            "[30]\tvalidation_0-aucpr:0.748241\n",
            "[31]\tvalidation_0-aucpr:0.749459\n",
            "[32]\tvalidation_0-aucpr:0.750289\n",
            "[33]\tvalidation_0-aucpr:0.751184\n",
            "[34]\tvalidation_0-aucpr:0.752323\n",
            "[35]\tvalidation_0-aucpr:0.753271\n",
            "[36]\tvalidation_0-aucpr:0.754232\n",
            "[37]\tvalidation_0-aucpr:0.754999\n",
            "[38]\tvalidation_0-aucpr:0.75585\n",
            "[39]\tvalidation_0-aucpr:0.756622\n",
            "[40]\tvalidation_0-aucpr:0.757208\n",
            "[41]\tvalidation_0-aucpr:0.757718\n",
            "[42]\tvalidation_0-aucpr:0.75829\n",
            "[43]\tvalidation_0-aucpr:0.758843\n",
            "[44]\tvalidation_0-aucpr:0.759473\n",
            "[45]\tvalidation_0-aucpr:0.760225\n",
            "[46]\tvalidation_0-aucpr:0.760721\n",
            "[47]\tvalidation_0-aucpr:0.761253\n",
            "[48]\tvalidation_0-aucpr:0.761598\n",
            "[49]\tvalidation_0-aucpr:0.762083\n",
            "[50]\tvalidation_0-aucpr:0.762447\n",
            "[51]\tvalidation_0-aucpr:0.762764\n",
            "[52]\tvalidation_0-aucpr:0.762883\n",
            "[53]\tvalidation_0-aucpr:0.763291\n",
            "[54]\tvalidation_0-aucpr:0.763642\n",
            "[55]\tvalidation_0-aucpr:0.763884\n",
            "[56]\tvalidation_0-aucpr:0.764221\n",
            "[57]\tvalidation_0-aucpr:0.764527\n",
            "[58]\tvalidation_0-aucpr:0.764938\n",
            "[59]\tvalidation_0-aucpr:0.765402\n",
            "[60]\tvalidation_0-aucpr:0.765628\n",
            "[61]\tvalidation_0-aucpr:0.76594\n",
            "[62]\tvalidation_0-aucpr:0.766105\n",
            "[63]\tvalidation_0-aucpr:0.766378\n",
            "[64]\tvalidation_0-aucpr:0.766563\n",
            "[65]\tvalidation_0-aucpr:0.766818\n",
            "[66]\tvalidation_0-aucpr:0.76696\n",
            "[67]\tvalidation_0-aucpr:0.767213\n",
            "[68]\tvalidation_0-aucpr:0.767329\n",
            "[69]\tvalidation_0-aucpr:0.767595\n",
            "[70]\tvalidation_0-aucpr:0.76784\n",
            "[71]\tvalidation_0-aucpr:0.768124\n",
            "[72]\tvalidation_0-aucpr:0.768346\n",
            "[73]\tvalidation_0-aucpr:0.768455\n",
            "[74]\tvalidation_0-aucpr:0.768657\n",
            "[75]\tvalidation_0-aucpr:0.768822\n",
            "[76]\tvalidation_0-aucpr:0.769131\n",
            "[77]\tvalidation_0-aucpr:0.769396\n",
            "[78]\tvalidation_0-aucpr:0.769623\n",
            "[79]\tvalidation_0-aucpr:0.769753\n",
            "[80]\tvalidation_0-aucpr:0.769997\n",
            "[81]\tvalidation_0-aucpr:0.770133\n",
            "[82]\tvalidation_0-aucpr:0.770226\n",
            "[83]\tvalidation_0-aucpr:0.770298\n",
            "[84]\tvalidation_0-aucpr:0.770422\n",
            "[85]\tvalidation_0-aucpr:0.770594\n",
            "[86]\tvalidation_0-aucpr:0.770845\n",
            "[87]\tvalidation_0-aucpr:0.770987\n",
            "[88]\tvalidation_0-aucpr:0.771134\n",
            "[89]\tvalidation_0-aucpr:0.771343\n",
            "[90]\tvalidation_0-aucpr:0.77143\n",
            "[91]\tvalidation_0-aucpr:0.771526\n",
            "[92]\tvalidation_0-aucpr:0.771637\n",
            "[93]\tvalidation_0-aucpr:0.771809\n",
            "[94]\tvalidation_0-aucpr:0.771953\n",
            "[95]\tvalidation_0-aucpr:0.772143\n",
            "[96]\tvalidation_0-aucpr:0.772247\n",
            "[97]\tvalidation_0-aucpr:0.772353\n",
            "[98]\tvalidation_0-aucpr:0.772515\n",
            "[99]\tvalidation_0-aucpr:0.772593\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82     63756\n",
            "           1       0.70      0.69      0.70     37316\n",
            "\n",
            "    accuracy                           0.78    101072\n",
            "   macro avg       0.76      0.76      0.76    101072\n",
            "weighted avg       0.78      0.78      0.78    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWiUHM7-jYzK"
      },
      "source": [
        "**Model 6: Cosine Distance + XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjXrT2WgakTB",
        "outputId": "89365229-54af-42a8-e8dc-649569269feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "    word = re.compile(r'\\w+')\n",
        "    words = word.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "def COSINE(q1, q2):\n",
        "    vector1 = text_to_vector(q1)\n",
        "    vector2 = text_to_vector(q2)\n",
        "    cosine_result = get_cosine(vector1, vector2)\n",
        "    return cosine_result\n",
        "\n",
        "df['cosine'] = df.apply(lambda x: COSINE(x['question1'], x['question2']), axis=1)\n",
        "a = 0 \n",
        "for i in range(a,a+10):\n",
        "    print(df.cosine[i])\n",
        "    print()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9449111825230682\n",
            "\n",
            "0.5368754921931592\n",
            "\n",
            "0.253546276418555\n",
            "\n",
            "0.0\n",
            "\n",
            "0.4193139346887673\n",
            "\n",
            "0.5564148840746571\n",
            "\n",
            "0.0\n",
            "\n",
            "0.5039526306789696\n",
            "\n",
            "0.8017837257372731\n",
            "\n",
            "0.4444444444444444\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osR2uh5fwBV",
        "outputId": "f41a3a31-4e6a-426c-f5b6-9dc846c7023e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = df.loc[:, df.columns == 'cosine']\n",
        "y = df['is_duplicate'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "[0]\tvalidation_0-aucpr:0.571106\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.572539\n",
            "[2]\tvalidation_0-aucpr:0.572827\n",
            "[3]\tvalidation_0-aucpr:0.57425\n",
            "[4]\tvalidation_0-aucpr:0.573966\n",
            "[5]\tvalidation_0-aucpr:0.574852\n",
            "[6]\tvalidation_0-aucpr:0.5756\n",
            "[7]\tvalidation_0-aucpr:0.575709\n",
            "[8]\tvalidation_0-aucpr:0.575836\n",
            "[9]\tvalidation_0-aucpr:0.576341\n",
            "[10]\tvalidation_0-aucpr:0.576407\n",
            "[11]\tvalidation_0-aucpr:0.576792\n",
            "[12]\tvalidation_0-aucpr:0.577149\n",
            "[13]\tvalidation_0-aucpr:0.577229\n",
            "[14]\tvalidation_0-aucpr:0.577384\n",
            "[15]\tvalidation_0-aucpr:0.577299\n",
            "[16]\tvalidation_0-aucpr:0.577496\n",
            "[17]\tvalidation_0-aucpr:0.577607\n",
            "[18]\tvalidation_0-aucpr:0.577764\n",
            "[19]\tvalidation_0-aucpr:0.577698\n",
            "[20]\tvalidation_0-aucpr:0.577618\n",
            "[21]\tvalidation_0-aucpr:0.577773\n",
            "[22]\tvalidation_0-aucpr:0.577735\n",
            "[23]\tvalidation_0-aucpr:0.577907\n",
            "[24]\tvalidation_0-aucpr:0.577834\n",
            "[25]\tvalidation_0-aucpr:0.577991\n",
            "[26]\tvalidation_0-aucpr:0.577942\n",
            "[27]\tvalidation_0-aucpr:0.577957\n",
            "[28]\tvalidation_0-aucpr:0.577865\n",
            "[29]\tvalidation_0-aucpr:0.577971\n",
            "[30]\tvalidation_0-aucpr:0.577907\n",
            "[31]\tvalidation_0-aucpr:0.577924\n",
            "[32]\tvalidation_0-aucpr:0.57787\n",
            "[33]\tvalidation_0-aucpr:0.577855\n",
            "[34]\tvalidation_0-aucpr:0.577822\n",
            "[35]\tvalidation_0-aucpr:0.577836\n",
            "Stopping. Best iteration:\n",
            "[25]\tvalidation_0-aucpr:0.577991\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.57      0.68     63756\n",
            "           1       0.52      0.81      0.63     37316\n",
            "\n",
            "    accuracy                           0.66    101072\n",
            "   macro avg       0.68      0.69      0.66    101072\n",
            "weighted avg       0.72      0.66      0.66    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}