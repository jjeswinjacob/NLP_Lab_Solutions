{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quoraFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPJsXNxtF3O/XVoki+jb7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjeswinjacob/NLP_Lab_Solutions/blob/master/quoraFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dituzY5HcegU"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAL3bgWuO0v",
        "outputId": "6e8e0577-c288-43ba-b635-6f06f9285a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import pandas as pd # data manipulation and analysis\n",
        "df = pd.read_csv('train.csv') # Returns a dataframe\n",
        "df.dropna(axis=0, inplace=True) # axis = 0 drops Rows with missing values and changes values in the same dataframe\n",
        "df.groupby(\"is_duplicate\")['id'].count().plot.bar()\n",
        "df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True) # Drop specified labels\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from string import punctuation"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Z1KNE5c2bp"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYZDudExbK7"
      },
      "source": [
        "def clean(text):\n",
        "    # Clean the text\n",
        "    text = re.sub(\" what's \", \" what is \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(\"can't\", \"can not\", text)\n",
        "    text = re.sub(\"n't\", \" not \", text)\n",
        "    text = re.sub(\"\\'re\", \" are \", text)\n",
        "    text = re.sub(\"\\'d\", \" would \", text)\n",
        "    text = re.sub(\"\\'ll\", \" will \", text)\n",
        "  \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
        "\n",
        "    # Lemmatizing Text\n",
        "    lemmatizer = WordNetLemmatizer() \n",
        "    text = ''.join([lemmatizer.lemmatize(c) for c in text])\n",
        "    \n",
        "    return text\n",
        "    \n",
        "df['question1'] = df['question1'].apply(clean) # axis = 0 by default and to apply clean on every row in given dataframe\n",
        "df['question2'] = df['question2'].apply(clean)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KomslrErvBca"
      },
      "source": [
        "Regularization Parameters Legend:\n",
        "\n",
        "* Gamma - Tree Complexity Parameter - Minimum loss reduction allowed for a split to occur. If Gain - Gamma = +ve, we keep node, else discard. So, we don't prune as long as we have a positive gain.\n",
        "\n",
        "* Alpha - L1 (Lasso) regularization on leaf weights, larger values mean more regularization - Larger values of Alpha helps us do away with useless features. Encourages values to go to zero. Reduces the amount each leaf contributes in output value\n",
        "\n",
        "* Lambda - L2 (Ridge) regularization on leaf weights - Introduces Bias to reduce Variance - When lambda = 0, we ignore this regularization. \n",
        "\n",
        "* scale_pos_weight set to ratio of negative class entities to positive class entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDuL_nrdLK7"
      },
      "source": [
        "**Model 1: BOW -> XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzQXDAQFqh5m",
        "outputId": "f3cfef92-e66b-4cb9-93e1-0d7f50fb48eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Countvectorizer lowercases all words by default\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "# The fit method learns the vocabulary of all tokens in the documents\n",
        "count_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = count_vect.transform(df['question1'].values)\n",
        "trainq2_trans = count_vect.transform(df['question2'].values)\n",
        "labels = df['is_duplicate'].values\n",
        "\n",
        "import scipy\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "y = labels\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18, stratify = y)\n",
        "\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "[0]\tvalidation_0-aucpr:0.679638\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.70193\n",
            "[2]\tvalidation_0-aucpr:0.71836\n",
            "[3]\tvalidation_0-aucpr:0.729554\n",
            "[4]\tvalidation_0-aucpr:0.735555\n",
            "[5]\tvalidation_0-aucpr:0.74137\n",
            "[6]\tvalidation_0-aucpr:0.745527\n",
            "[7]\tvalidation_0-aucpr:0.750151\n",
            "[8]\tvalidation_0-aucpr:0.754121\n",
            "[9]\tvalidation_0-aucpr:0.758675\n",
            "[10]\tvalidation_0-aucpr:0.762979\n",
            "[11]\tvalidation_0-aucpr:0.767085\n",
            "[12]\tvalidation_0-aucpr:0.770508\n",
            "[13]\tvalidation_0-aucpr:0.772949\n",
            "[14]\tvalidation_0-aucpr:0.776118\n",
            "[15]\tvalidation_0-aucpr:0.778538\n",
            "[16]\tvalidation_0-aucpr:0.780527\n",
            "[17]\tvalidation_0-aucpr:0.782577\n",
            "[18]\tvalidation_0-aucpr:0.784386\n",
            "[19]\tvalidation_0-aucpr:0.786479\n",
            "[20]\tvalidation_0-aucpr:0.787911\n",
            "[21]\tvalidation_0-aucpr:0.788909\n",
            "[22]\tvalidation_0-aucpr:0.790754\n",
            "[23]\tvalidation_0-aucpr:0.792262\n",
            "[24]\tvalidation_0-aucpr:0.793442\n",
            "[25]\tvalidation_0-aucpr:0.794316\n",
            "[26]\tvalidation_0-aucpr:0.795235\n",
            "[27]\tvalidation_0-aucpr:0.79598\n",
            "[28]\tvalidation_0-aucpr:0.797275\n",
            "[29]\tvalidation_0-aucpr:0.797884\n",
            "[30]\tvalidation_0-aucpr:0.798519\n",
            "[31]\tvalidation_0-aucpr:0.798985\n",
            "[32]\tvalidation_0-aucpr:0.799807\n",
            "[33]\tvalidation_0-aucpr:0.800792\n",
            "[34]\tvalidation_0-aucpr:0.801711\n",
            "[35]\tvalidation_0-aucpr:0.802217\n",
            "[36]\tvalidation_0-aucpr:0.803273\n",
            "[37]\tvalidation_0-aucpr:0.803756\n",
            "[38]\tvalidation_0-aucpr:0.804919\n",
            "[39]\tvalidation_0-aucpr:0.805541\n",
            "[40]\tvalidation_0-aucpr:0.806081\n",
            "[41]\tvalidation_0-aucpr:0.806655\n",
            "[42]\tvalidation_0-aucpr:0.807214\n",
            "[43]\tvalidation_0-aucpr:0.807657\n",
            "[44]\tvalidation_0-aucpr:0.8082\n",
            "[45]\tvalidation_0-aucpr:0.808745\n",
            "[46]\tvalidation_0-aucpr:0.809106\n",
            "[47]\tvalidation_0-aucpr:0.809598\n",
            "[48]\tvalidation_0-aucpr:0.810267\n",
            "[49]\tvalidation_0-aucpr:0.810644\n",
            "[50]\tvalidation_0-aucpr:0.811449\n",
            "[51]\tvalidation_0-aucpr:0.811832\n",
            "[52]\tvalidation_0-aucpr:0.812203\n",
            "[53]\tvalidation_0-aucpr:0.812592\n",
            "[54]\tvalidation_0-aucpr:0.813007\n",
            "[55]\tvalidation_0-aucpr:0.813348\n",
            "[56]\tvalidation_0-aucpr:0.813892\n",
            "[57]\tvalidation_0-aucpr:0.814198\n",
            "[58]\tvalidation_0-aucpr:0.814584\n",
            "[59]\tvalidation_0-aucpr:0.81485\n",
            "[60]\tvalidation_0-aucpr:0.815111\n",
            "[61]\tvalidation_0-aucpr:0.815502\n",
            "[62]\tvalidation_0-aucpr:0.815887\n",
            "[63]\tvalidation_0-aucpr:0.816595\n",
            "[64]\tvalidation_0-aucpr:0.816911\n",
            "[65]\tvalidation_0-aucpr:0.817304\n",
            "[66]\tvalidation_0-aucpr:0.817714\n",
            "[67]\tvalidation_0-aucpr:0.818053\n",
            "[68]\tvalidation_0-aucpr:0.818296\n",
            "[69]\tvalidation_0-aucpr:0.818606\n",
            "[70]\tvalidation_0-aucpr:0.81905\n",
            "[71]\tvalidation_0-aucpr:0.819391\n",
            "[72]\tvalidation_0-aucpr:0.819817\n",
            "[73]\tvalidation_0-aucpr:0.820271\n",
            "[74]\tvalidation_0-aucpr:0.820764\n",
            "[75]\tvalidation_0-aucpr:0.820995\n",
            "[76]\tvalidation_0-aucpr:0.821304\n",
            "[77]\tvalidation_0-aucpr:0.821543\n",
            "[78]\tvalidation_0-aucpr:0.821759\n",
            "[79]\tvalidation_0-aucpr:0.822223\n",
            "[80]\tvalidation_0-aucpr:0.822477\n",
            "[81]\tvalidation_0-aucpr:0.822679\n",
            "[82]\tvalidation_0-aucpr:0.822871\n",
            "[83]\tvalidation_0-aucpr:0.823646\n",
            "[84]\tvalidation_0-aucpr:0.823804\n",
            "[85]\tvalidation_0-aucpr:0.823943\n",
            "[86]\tvalidation_0-aucpr:0.824184\n",
            "[87]\tvalidation_0-aucpr:0.824333\n",
            "[88]\tvalidation_0-aucpr:0.824603\n",
            "[89]\tvalidation_0-aucpr:0.824847\n",
            "[90]\tvalidation_0-aucpr:0.825067\n",
            "[91]\tvalidation_0-aucpr:0.825754\n",
            "[92]\tvalidation_0-aucpr:0.825976\n",
            "[93]\tvalidation_0-aucpr:0.826121\n",
            "[94]\tvalidation_0-aucpr:0.82626\n",
            "[95]\tvalidation_0-aucpr:0.826426\n",
            "[96]\tvalidation_0-aucpr:0.826596\n",
            "[97]\tvalidation_0-aucpr:0.826735\n",
            "[98]\tvalidation_0-aucpr:0.82698\n",
            "[99]\tvalidation_0-aucpr:0.827379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84     63756\n",
            "           1       0.72      0.77      0.74     37316\n",
            "\n",
            "    accuracy                           0.80    101072\n",
            "   macro avg       0.79      0.80      0.79    101072\n",
            "weighted avg       0.81      0.80      0.80    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r13GOGJ0X0fn"
      },
      "source": [
        "Legend:\n",
        "* Precision is out of all predictions of one class, how many are right. TP/ (TP + FP) eg. Out of all duplicate prediction, how many are actually duplicate\n",
        "\n",
        "* Recall is out of all entities of one class, how many are correctly predicted. TP/ (TP + FN) eg. Out of all duplicate questions in dataset, how many are predicted correctly\n",
        "\n",
        "* f1-score = 2(Precision * Recall)/ (Precision + Recall) - Harmonic Mean of Precision and Recall\n",
        " f1-score = TP/ (TP + (FP + FN)/ 2)\n",
        "\n",
        "* Macro average is unweighted average of probabilities in both class.\n",
        "\n",
        "* Support is the number of actual occurrences of the class in the specified dataset. \n",
        "\n",
        "* Weighted average gives the support-weighted mean per label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr8hBPZgdUWj"
      },
      "source": [
        "**Model 2: TFIDF + XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRgSbOOexGzc",
        "outputId": "6039d5a8-1483-4d56-8151-14d6a21c924a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
        "tfidf_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = tfidf_vect.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect.transform(df['question2'].values)\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-aucpr:0.678644\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.702687\n",
            "[2]\tvalidation_0-aucpr:0.719437\n",
            "[3]\tvalidation_0-aucpr:0.731345\n",
            "[4]\tvalidation_0-aucpr:0.74073\n",
            "[5]\tvalidation_0-aucpr:0.747252\n",
            "[6]\tvalidation_0-aucpr:0.752934\n",
            "[7]\tvalidation_0-aucpr:0.758068\n",
            "[8]\tvalidation_0-aucpr:0.762637\n",
            "[9]\tvalidation_0-aucpr:0.767321\n",
            "[10]\tvalidation_0-aucpr:0.771125\n",
            "[11]\tvalidation_0-aucpr:0.774424\n",
            "[12]\tvalidation_0-aucpr:0.777103\n",
            "[13]\tvalidation_0-aucpr:0.780107\n",
            "[14]\tvalidation_0-aucpr:0.78265\n",
            "[15]\tvalidation_0-aucpr:0.785446\n",
            "[16]\tvalidation_0-aucpr:0.788364\n",
            "[17]\tvalidation_0-aucpr:0.790417\n",
            "[18]\tvalidation_0-aucpr:0.792057\n",
            "[19]\tvalidation_0-aucpr:0.793502\n",
            "[20]\tvalidation_0-aucpr:0.795442\n",
            "[21]\tvalidation_0-aucpr:0.797063\n",
            "[22]\tvalidation_0-aucpr:0.798316\n",
            "[23]\tvalidation_0-aucpr:0.799152\n",
            "[24]\tvalidation_0-aucpr:0.800078\n",
            "[25]\tvalidation_0-aucpr:0.80103\n",
            "[26]\tvalidation_0-aucpr:0.802783\n",
            "[27]\tvalidation_0-aucpr:0.803474\n",
            "[28]\tvalidation_0-aucpr:0.804241\n",
            "[29]\tvalidation_0-aucpr:0.804925\n",
            "[30]\tvalidation_0-aucpr:0.805898\n",
            "[31]\tvalidation_0-aucpr:0.806461\n",
            "[32]\tvalidation_0-aucpr:0.807262\n",
            "[33]\tvalidation_0-aucpr:0.808921\n",
            "[34]\tvalidation_0-aucpr:0.809483\n",
            "[35]\tvalidation_0-aucpr:0.809938\n",
            "[36]\tvalidation_0-aucpr:0.810796\n",
            "[37]\tvalidation_0-aucpr:0.811325\n",
            "[38]\tvalidation_0-aucpr:0.811882\n",
            "[39]\tvalidation_0-aucpr:0.812344\n",
            "[40]\tvalidation_0-aucpr:0.812722\n",
            "[41]\tvalidation_0-aucpr:0.813216\n",
            "[42]\tvalidation_0-aucpr:0.813715\n",
            "[43]\tvalidation_0-aucpr:0.814114\n",
            "[44]\tvalidation_0-aucpr:0.815501\n",
            "[45]\tvalidation_0-aucpr:0.816097\n",
            "[46]\tvalidation_0-aucpr:0.816686\n",
            "[47]\tvalidation_0-aucpr:0.817074\n",
            "[48]\tvalidation_0-aucpr:0.817519\n",
            "[49]\tvalidation_0-aucpr:0.817922\n",
            "[50]\tvalidation_0-aucpr:0.818154\n",
            "[51]\tvalidation_0-aucpr:0.819029\n",
            "[52]\tvalidation_0-aucpr:0.819377\n",
            "[53]\tvalidation_0-aucpr:0.819935\n",
            "[54]\tvalidation_0-aucpr:0.820199\n",
            "[55]\tvalidation_0-aucpr:0.820547\n",
            "[56]\tvalidation_0-aucpr:0.821002\n",
            "[57]\tvalidation_0-aucpr:0.821452\n",
            "[58]\tvalidation_0-aucpr:0.821763\n",
            "[59]\tvalidation_0-aucpr:0.822064\n",
            "[60]\tvalidation_0-aucpr:0.822466\n",
            "[61]\tvalidation_0-aucpr:0.822741\n",
            "[62]\tvalidation_0-aucpr:0.82321\n",
            "[63]\tvalidation_0-aucpr:0.823789\n",
            "[64]\tvalidation_0-aucpr:0.824139\n",
            "[65]\tvalidation_0-aucpr:0.824417\n",
            "[66]\tvalidation_0-aucpr:0.824766\n",
            "[67]\tvalidation_0-aucpr:0.825145\n",
            "[68]\tvalidation_0-aucpr:0.825515\n",
            "[69]\tvalidation_0-aucpr:0.825797\n",
            "[70]\tvalidation_0-aucpr:0.826122\n",
            "[71]\tvalidation_0-aucpr:0.826425\n",
            "[72]\tvalidation_0-aucpr:0.826754\n",
            "[73]\tvalidation_0-aucpr:0.827117\n",
            "[74]\tvalidation_0-aucpr:0.827382\n",
            "[75]\tvalidation_0-aucpr:0.827702\n",
            "[76]\tvalidation_0-aucpr:0.828104\n",
            "[77]\tvalidation_0-aucpr:0.828352\n",
            "[78]\tvalidation_0-aucpr:0.828595\n",
            "[79]\tvalidation_0-aucpr:0.828776\n",
            "[80]\tvalidation_0-aucpr:0.829004\n",
            "[81]\tvalidation_0-aucpr:0.829369\n",
            "[82]\tvalidation_0-aucpr:0.829541\n",
            "[83]\tvalidation_0-aucpr:0.829738\n",
            "[84]\tvalidation_0-aucpr:0.830067\n",
            "[85]\tvalidation_0-aucpr:0.830288\n",
            "[86]\tvalidation_0-aucpr:0.83055\n",
            "[87]\tvalidation_0-aucpr:0.830859\n",
            "[88]\tvalidation_0-aucpr:0.831285\n",
            "[89]\tvalidation_0-aucpr:0.831463\n",
            "[90]\tvalidation_0-aucpr:0.83186\n",
            "[91]\tvalidation_0-aucpr:0.832111\n",
            "[92]\tvalidation_0-aucpr:0.832306\n",
            "[93]\tvalidation_0-aucpr:0.832537\n",
            "[94]\tvalidation_0-aucpr:0.832761\n",
            "[95]\tvalidation_0-aucpr:0.832944\n",
            "[96]\tvalidation_0-aucpr:0.833126\n",
            "[97]\tvalidation_0-aucpr:0.833331\n",
            "[98]\tvalidation_0-aucpr:0.833514\n",
            "[99]\tvalidation_0-aucpr:0.833676\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85     63633\n",
            "           1       0.74      0.75      0.75     37439\n",
            "\n",
            "    accuracy                           0.81    101072\n",
            "   macro avg       0.80      0.80      0.80    101072\n",
            "weighted avg       0.81      0.81      0.81    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybryLUUsdfJu"
      },
      "source": [
        "**Model 3: Character Level TFIDF -> XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnvkOr_JLDaW",
        "outputId": "048eaa79-f42b-473e-ad13-a5037806620d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,4))\n",
        "tfidf_vect_ngram_chars.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
        "\n",
        "trainq1_trans = tfidf_vect_ngram_chars.transform(df['question1'].values)\n",
        "trainq2_trans = tfidf_vect_ngram_chars.transform(df['question2'].values)\n",
        "X = scipy.sparse.hstack((trainq1_trans,trainq2_trans))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y, test_size = 0.25, random_state = 18)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(max_depth=60, learning_rate=0.15, n_estimators=100, objective='binary:logistic', gamma=0, reg_alpha=4, reg_lambda=0, scale_pos_weight = 1.7)\n",
        "xgb_model = xgb_model.fit(X_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', eval_set = [(X_valid, y_valid)]) \n",
        "xgb_prediction = xgb_model.predict(X_valid)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_valid, xgb_prediction))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-aucpr:0.656739\n",
            "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-aucpr:0.71425\n",
            "[2]\tvalidation_0-aucpr:0.739088\n",
            "[3]\tvalidation_0-aucpr:0.754692\n",
            "[4]\tvalidation_0-aucpr:0.766862\n",
            "[5]\tvalidation_0-aucpr:0.776422\n",
            "[6]\tvalidation_0-aucpr:0.784029\n",
            "[7]\tvalidation_0-aucpr:0.790575\n",
            "[8]\tvalidation_0-aucpr:0.79483\n",
            "[9]\tvalidation_0-aucpr:0.79899\n",
            "[10]\tvalidation_0-aucpr:0.803742\n",
            "[11]\tvalidation_0-aucpr:0.807545\n",
            "[12]\tvalidation_0-aucpr:0.810842\n",
            "[13]\tvalidation_0-aucpr:0.813623\n",
            "[14]\tvalidation_0-aucpr:0.816389\n",
            "[15]\tvalidation_0-aucpr:0.81845\n",
            "[16]\tvalidation_0-aucpr:0.821171\n",
            "[17]\tvalidation_0-aucpr:0.823928\n",
            "[18]\tvalidation_0-aucpr:0.826198\n",
            "[19]\tvalidation_0-aucpr:0.828533\n",
            "[20]\tvalidation_0-aucpr:0.830801\n",
            "[21]\tvalidation_0-aucpr:0.832707\n",
            "[22]\tvalidation_0-aucpr:0.834134\n",
            "[23]\tvalidation_0-aucpr:0.835662\n",
            "[24]\tvalidation_0-aucpr:0.837661\n",
            "[25]\tvalidation_0-aucpr:0.838971\n",
            "[26]\tvalidation_0-aucpr:0.840289\n",
            "[27]\tvalidation_0-aucpr:0.841598\n",
            "[28]\tvalidation_0-aucpr:0.84284\n",
            "[29]\tvalidation_0-aucpr:0.844032\n",
            "[30]\tvalidation_0-aucpr:0.845153\n",
            "[31]\tvalidation_0-aucpr:0.846419\n",
            "[32]\tvalidation_0-aucpr:0.847391\n",
            "[33]\tvalidation_0-aucpr:0.848157\n",
            "[34]\tvalidation_0-aucpr:0.84954\n",
            "[35]\tvalidation_0-aucpr:0.85073\n",
            "[36]\tvalidation_0-aucpr:0.851317\n",
            "[37]\tvalidation_0-aucpr:0.852386\n",
            "[38]\tvalidation_0-aucpr:0.85349\n",
            "[39]\tvalidation_0-aucpr:0.854209\n",
            "[40]\tvalidation_0-aucpr:0.855066\n",
            "[41]\tvalidation_0-aucpr:0.85579\n",
            "[42]\tvalidation_0-aucpr:0.856703\n",
            "[43]\tvalidation_0-aucpr:0.857439\n",
            "[44]\tvalidation_0-aucpr:0.858233\n",
            "[45]\tvalidation_0-aucpr:0.858896\n",
            "[46]\tvalidation_0-aucpr:0.85956\n",
            "[47]\tvalidation_0-aucpr:0.860212\n",
            "[48]\tvalidation_0-aucpr:0.860861\n",
            "[49]\tvalidation_0-aucpr:0.861465\n",
            "[50]\tvalidation_0-aucpr:0.862118\n",
            "[51]\tvalidation_0-aucpr:0.862485\n",
            "[52]\tvalidation_0-aucpr:0.863018\n",
            "[53]\tvalidation_0-aucpr:0.863738\n",
            "[54]\tvalidation_0-aucpr:0.864262\n",
            "[55]\tvalidation_0-aucpr:0.864845\n",
            "[56]\tvalidation_0-aucpr:0.865221\n",
            "[57]\tvalidation_0-aucpr:0.86587\n",
            "[58]\tvalidation_0-aucpr:0.866356\n",
            "[59]\tvalidation_0-aucpr:0.866806\n",
            "[60]\tvalidation_0-aucpr:0.867175\n",
            "[61]\tvalidation_0-aucpr:0.867559\n",
            "[62]\tvalidation_0-aucpr:0.868018\n",
            "[63]\tvalidation_0-aucpr:0.868384\n",
            "[64]\tvalidation_0-aucpr:0.868716\n",
            "[65]\tvalidation_0-aucpr:0.868936\n",
            "[66]\tvalidation_0-aucpr:0.869344\n",
            "[67]\tvalidation_0-aucpr:0.869562\n",
            "[68]\tvalidation_0-aucpr:0.869746\n",
            "[69]\tvalidation_0-aucpr:0.870027\n",
            "[70]\tvalidation_0-aucpr:0.870148\n",
            "[71]\tvalidation_0-aucpr:0.870419\n",
            "[72]\tvalidation_0-aucpr:0.870751\n",
            "[73]\tvalidation_0-aucpr:0.871007\n",
            "[74]\tvalidation_0-aucpr:0.871241\n",
            "[75]\tvalidation_0-aucpr:0.87145\n",
            "[76]\tvalidation_0-aucpr:0.871633\n",
            "[77]\tvalidation_0-aucpr:0.871931\n",
            "[78]\tvalidation_0-aucpr:0.872349\n",
            "[79]\tvalidation_0-aucpr:0.872523\n",
            "[80]\tvalidation_0-aucpr:0.872836\n",
            "[81]\tvalidation_0-aucpr:0.87302\n",
            "[82]\tvalidation_0-aucpr:0.873275\n",
            "[83]\tvalidation_0-aucpr:0.87362\n",
            "[84]\tvalidation_0-aucpr:0.873794\n",
            "[85]\tvalidation_0-aucpr:0.873968\n",
            "[86]\tvalidation_0-aucpr:0.874107\n",
            "[87]\tvalidation_0-aucpr:0.874331\n",
            "[88]\tvalidation_0-aucpr:0.874416\n",
            "[89]\tvalidation_0-aucpr:0.874638\n",
            "[90]\tvalidation_0-aucpr:0.874793\n",
            "[91]\tvalidation_0-aucpr:0.874985\n",
            "[92]\tvalidation_0-aucpr:0.875084\n",
            "[93]\tvalidation_0-aucpr:0.875219\n",
            "[94]\tvalidation_0-aucpr:0.875443\n",
            "[95]\tvalidation_0-aucpr:0.875551\n",
            "[96]\tvalidation_0-aucpr:0.875684\n",
            "[97]\tvalidation_0-aucpr:0.8759\n",
            "[98]\tvalidation_0-aucpr:0.876065\n",
            "[99]\tvalidation_0-aucpr:0.876244\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87     63633\n",
            "           1       0.81      0.75      0.77     37439\n",
            "\n",
            "    accuracy                           0.84    101072\n",
            "   macro avg       0.83      0.82      0.82    101072\n",
            "weighted avg       0.84      0.84      0.84    101072\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzq6vWoDv1sz"
      },
      "source": [
        "**Conclusion**: Three different models were used to classify the pairs of questions as duplicate or not duplicate. The word level BOW model gave an accuracy of 80%, the word level TFIDF gave an accuracy of 81% - a slightly better improvement owing to the removal of useless words. The character level TFIDF consisting of bigrams, trigrams, and 4-grams gave the best accuracy of 84%. This is owing to the reason that there are various different words with the same meaning, which can't be captured by word level BOW or word level TFIDF eg. lover and loving. Thus, where word level BOW and TFIDF lose out on valuable information, character level n-gram TFIDF can capture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86FKISONxxU0"
      },
      "source": [
        "**Future Enhancements**: \n",
        "* Parts of Speech, Cosine distance, and the Word Mover's Distance can be used to capture more information from the questions to help classify with more accuracy. \n",
        "\n",
        "* The n-gram range could be increased to capture 5 grams."
      ]
    }
  ]
}